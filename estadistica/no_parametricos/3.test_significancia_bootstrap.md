# Test de significancia con bootstrap

### El problema real: evaluar sin fórmulas

Imaginá que desarrollás una estrategia de trading, la probás sobre un año de datos, y te da una ganancia promedio de +7%. ¿Eso prueba que la estrategia es buena? ¿O pudo haber sido suerte?

En estadística clásica, esta pregunta se responde con test de hipótesis, fórmulas, y suposiciones de normalidad. Pero nosotros queremos hacerlo sin suponer nada. Queremos una forma de evaluar si ese resultado **es excepcional o no**, usando solo nuestros propios datos.

Ahí es donde entra el **test de significancia con bootstrap**.

### La lógica intuitiva

Si la estrategia **no tuviera ningún efecto real** (es decir, si fuera puro azar), ¿qué tan probable sería obtener un resultado como el que obtuvimos?

Con el bootstrap podemos simular **qué resultados serían esperables si la estrategia no funcionara realmente**, y ver si lo que observamos se destaca.

Esto se parece mucho a lo que hace el p-valor en la estadística clásica, pero sin fórmulas ni distribuciones teóricas. Lo hacemos desde abajo, **simulando la distribución nula**.

### Ejemplo aplicado

Tenés una serie de retornos diarios de una estrategia:

```
[+1%, -0.5%, +2%, +0.3%, -1%, +1.5%, -0.7%, ...]
```

Querés saber si el retorno promedio observado (por ejemplo, +0.7% diario) es significativamente mayor que lo que obtendrías con una estrategia sin efecto real.

Una forma de simular esa “estrategia sin efecto” es:

* Centrar los datos (restar la media a todos los valores, para que el promedio sea 0)

* Luego hacer bootstrap sobre esa serie centrada

* En cada muestra, calcular la media

Esto genera una distribución empírica de medias bajo la hipótesis nula (_no hay efecto_).

Luego simplemente observás:

* ¿Qué tan lejos está tu media real de esa distribución?

* ¿Cuántas muestras tienen una media tan extrema o más que la observada?

Eso te da una medida de significancia empírica: **cuán inusual es tu resultado si la estrategia no tuviera efecto real**.

### ¿Y si no centramos los datos?

Otra opción es **no centrar** los datos antes de hacer bootstrap. En este caso, simplemente usamos la muestra tal como está y generamos muchas muestras bootstrap con reemplazo. En cada una calculamos la media (o el estadístico de interés) y luego comparamos el resultado observado con esa distribución.

Esto responde a otra pregunta:

> “¿Qué tan raro es este resultado comparado con otros resultados que podrían haber surgido de este mismo sistema?”

Esta lógica **no parte de una hipótesis nula explícita** como “la media es 0”, sino que toma los datos observados como representativos de la variabilidad del sistema, y se pregunta si lo que observamos es raro dentro de esa misma lógica.

Es decir:

* No estás construyendo una distribución nula como en el test formal

* Estás usando bootstrap como un **benchmark empírico** sobre tu propio sistema

Esto es útil si:

* No querés hacer un test estricto, sino tener una idea de cuán estable o confiable es tu estadístico

* Sos consciente de que tus datos podrían tener algún efecto real, y no querés anularlo al centrar

**Advertencia:** si tu muestra incluye sesgos o efectos reales, este enfoque podría subestimar la significancia, ya que no simula una situación nula, sino algo más parecido a “el sistema tal como lo tengo”.

### Interpretación del resultado

Si solo 3 de las 1000 muestras bootstrap superaron tu media real, podés decir que:

* Hay un 0.3% de chance de que ese resultado se dé por azar bajo la hipótesis nula

* Es decir, **tu resultado es significativo con un p-valor empírico de 0.003**

### Ventajas de este método

* No requiere normalidad ni varianzas iguales

* Funciona con cualquier estadístico (no solo la media)

* Es visual, comprensible y flexible

### Notas conceptuales

* Este método genera una distribución nula **empírica**, basada en remuestreos

* No usa fórmulas ni tablas: todo se simula

* Es una forma no paramétrica de test de hipótesis

* Puede ser de una cola o dos colas, según la hipótesis que se quiera probar

* El resultado se interpreta como un **p-valor empírico**

***

En la próxima ficha veremos cómo usar el bootstrap para estimar otras medidas más allá de la media, como el drawdown, los percentiles o el payoff. Porque no todo se resume en promedios.
